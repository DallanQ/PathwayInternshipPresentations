{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ee7fb7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DallanQ/PathwayInternshipPresentations/blob/main/07B_QA_Project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230ca5f",
   "metadata": {},
   "source": [
    "# QA Project\n",
    "\n",
    "Build your own question-answering system! In this project you will use everything you've learned so far to build your own question-answering system from scratch. This notebook contains an outline to help you.\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "You can open this notebook in google colab using the link at the top of the notebook, or copy and paste the contents into your own notebook.\n",
    "\n",
    "### Pair programming\n",
    "\n",
    "I want you to work in pairs for this project in preparation for working in pairs on the group project. I will assign the pairs. You will start on Wednesday and present your projects on Friday. Both Ryan and I have created Question-Answering systems before. Feel free to ask us for help if you need it.\n",
    "\n",
    "### API Keys\n",
    "\n",
    "You will need 2 API Keys for this project\n",
    "- OpenAI: Use the key you received for the LearnPrompting course in week 2\n",
    "  - please be careful how often you make OpenAI calls. They cost me money...\n",
    "- Pinecone: Sign up for a free account at https://www.pinecone.io/\n",
    "  - the free account allows you to create one pinecone database\n",
    "  \n",
    "### Resources\n",
    "\n",
    "You can refer to the following resources as you build your project. You can finally use Codeium if you want.\n",
    "- DeepLearning.ai course: https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/\n",
    "- Pinecone and OpenAI example: https://www.youtube.com/watch?v=dRUIGgNBvVk\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/00-build-index.ipynb\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/01-making-queries.ipynb\n",
    "      - This notebook uses an older GPT 3 model for text generation\n",
    "- ILoveConference \n",
    "  - build index: https://github.com/iloveconference/models/blob/main/notebooks/20_index.ipynb\n",
    "  - make queries: https://github.com/iloveconference/server/blob/main/server/main.py#L111\n",
    "      - This notebook uses the new GPT 3.5 model for text generation. You should use this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2b534",
   "metadata": {},
   "source": [
    "## Set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc2a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"openai key value goes here\"\n",
    "PINECONE_API_KEY=\"pinecone key value goes here\"\n",
    "PINECONE_ENV=\"pinecone environment (region) goes here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d845eac",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pinecone-client pandas\n",
    "# install other libraries as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007f145",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ee239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a946f4",
   "metadata": {},
   "source": [
    "## Initialize OpenAI and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac035d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be5c0b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/DallanQ/PathwayInternshipPresentations/main/pair_project_data.csv\"\n",
    "data = pd.read_csv(data_path, names=['ref', 'text']).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eb67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the data to make sure you understand the format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b9ede",
   "metadata": {},
   "source": [
    "## Generate embeddings\n",
    "\n",
    "Instead of generating embeddings in a separate step, you might want to generate the embeddings when you index the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f016b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code goes either here or in the indexing step below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a074016",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31630502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing code codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d78d080",
   "metadata": {},
   "source": [
    "## Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a question variable to a question you want to ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09057237",
   "metadata": {},
   "source": [
    "## Generate an embedding for the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fd8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code for the question goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7368ff",
   "metadata": {},
   "source": [
    "## Query index for passages that are likely to answer to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd77dc",
   "metadata": {},
   "source": [
    "## Generate prompt from returned passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f241653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt generation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754059fb",
   "metadata": {},
   "source": [
    "## Send prompt to text generation model and display the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1c2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PathwayInternshipPresentations",
   "language": "python",
   "name": "pathwayinternshippresentations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
