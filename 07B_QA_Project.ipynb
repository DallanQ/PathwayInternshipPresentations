{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a63faf8e",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DallanQ/PathwayInternshipPresentations/blob/main/07B_QA_Project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230ca5f",
   "metadata": {},
   "source": [
    "# QA Project\n",
    "\n",
    "Build your own question-answering system! In this project you will use everything you've learned so far to build your own question-answering system from scratch. This notebook contains an outline to help you.\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "You can open this notebook in google colab using the link at the top of the notebook, or copy and paste the contents into your own notebook.\n",
    "\n",
    "### Pair programming\n",
    "\n",
    "I want you to work in pairs for this project in preparation for working in pairs on the group project. I will assign the pairs. You will start on Wednesday and present your projects on Friday. Both Ryan and I have created Question-Answering systems before. Feel free to ask us for help if you need it.\n",
    "\n",
    "### API Keys\n",
    "\n",
    "You will need 2 API Keys for this project\n",
    "- OpenAI: Use the key you received for the LearnPrompting course in week 2\n",
    "  - please be careful how often you make OpenAI calls. They cost me money...\n",
    "- Pinecone: Sign up for a free account at https://www.pinecone.io/\n",
    "  - the free account allows you to create one pinecone database\n",
    "  \n",
    "### Resources\n",
    "\n",
    "You can refer to the following resources as you build your project. You can finally use Codeium if you want.\n",
    "- DeepLearning.ai course: https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/\n",
    "- Pinecone and OpenAI example: https://www.youtube.com/watch?v=dRUIGgNBvVk\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/00-build-index.ipynb\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/01-making-queries.ipynb\n",
    "      - This notebook uses an older GPT 3 model for text generation\n",
    "- ILoveConference \n",
    "  - build index: https://github.com/iloveconference/models/blob/main/notebooks/20_index.ipynb\n",
    "  - make queries: https://github.com/iloveconference/server/blob/main/server/main.py#L111\n",
    "      - This notebook uses the new GPT 3.5 model for text generation. You should use this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d845eac",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a82d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pinecone-client pandas python-dotenv\n",
    "# install other libraries as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007f145",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8ee239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3a0b5f",
   "metadata": {},
   "source": [
    "## Set API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5c7bb",
   "metadata": {},
   "source": [
    "### If you are running on Google Colab\n",
    "\n",
    "Set your API keys here as below, and don't check this file into github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f635948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"openai key value goes here\"\n",
    "PINECONE_API_KEY=\"pinecone key value goes here\"\n",
    "PINECONE_ENV=\"pinecone environment (region) goes here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fac491",
   "metadata": {},
   "source": [
    "### If you are running this notebook locally\n",
    "\n",
    "You want to make sure your API keys aren't accidentally checked in to github. To do this you will store them in a file named `.env` and make sure git ignores that file. Then you will use the `dotenv` notebook extension to load the variables from your `.env` file into operating system environment variables and you will read them from the operating system environment.\n",
    "\n",
    "1. Edit your `.gitignore` file and add the line `.env`\n",
    "2. Create a `.env` file, add the three lines above to the file, inserting your API keys, and save the file\n",
    "3. Execute `git status` and make sure your new `.env` file **does not** show up in the list of untracked files\n",
    "4. Uncomment the lines in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690421df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext dotenv\n",
    "# %dotenv\n",
    "# OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "# PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "# PINECONE_ENV = os.environ[\"PINECONE_ENV\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a946f4",
   "metadata": {},
   "source": [
    "## Initialize OpenAI and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac035d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be5c0b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead2b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/DallanQ/PathwayInternshipPresentations/main/pair_project_data.csv\"\n",
    "data = pd.read_csv(data_path, names=['ref', 'text']).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ffebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the data to make sure you understand the format\n",
    "print(len(data))\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87300c",
   "metadata": {},
   "source": [
    "## Generate embeddings\n",
    "\n",
    "Instead of generating embeddings in a separate step, you might want to generate the embeddings when you index the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec763b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code goes either here or in the indexing step below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e4ada",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc1bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing code codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a83d1",
   "metadata": {},
   "source": [
    "## Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a question variable to a question you want to ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c69fae8",
   "metadata": {},
   "source": [
    "## Generate an embedding for the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b391e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code for the question goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774fb9f",
   "metadata": {},
   "source": [
    "## Query index for passages that are likely to answer to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c064d",
   "metadata": {},
   "source": [
    "## Generate prompt from returned passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8553a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt generation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9f131",
   "metadata": {},
   "source": [
    "## Send prompt to text generation model and display the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PathwayInternshipPresentations",
   "language": "python",
   "name": "pathwayinternshippresentations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
