{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5dddc38",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DallanQ/PathwayInternshipPresentations/blob/main/07B_Pair_Project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230ca5f",
   "metadata": {},
   "source": [
    "# Pair Project\n",
    "\n",
    "Build your own question-answering system! In this project you will use everything you've learned so far to build your own question-answering system from scratch. This notebook contains an outline to help you.\n",
    "\n",
    "### Google Colab\n",
    "\n",
    "You can open this notebook in google colab using the link at the top of the notebook, or copy and paste the contents into your own notebook.\n",
    "\n",
    "### Pair programming\n",
    "\n",
    "I want you to work in pairs for this project in preparation for working in pairs on the group project. I will assign the pairs. You will start on Wednesday and present your projects on Friday. Both Ryan and I have created Question-Answering systems before. Feel free to ask us for help if you need it.\n",
    "\n",
    "### API Keys\n",
    "\n",
    "You will need 2 API Keys for this project\n",
    "- OpenAI: Use the key you received for the LearnPrompting course in week 2\n",
    "  - please be careful how often you make OpenAI calls. They cost me money...\n",
    "- Pinecone: Sign up for a free account at https://www.pinecone.io/\n",
    "  - the free account allows you to create one pinecone database\n",
    "  \n",
    "### Resources\n",
    "\n",
    "You can refer to the following resources as you build your project. You can finally use Codeium if you want.\n",
    "- DeepLearning.ai course: https://www.deeplearning.ai/short-courses/google-cloud-vertex-ai/\n",
    "- Pinecone and OpenAI example: https://www.youtube.com/watch?v=dRUIGgNBvVk\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/00-build-index.ipynb\n",
    "  - https://github.com/pinecone-io/examples/blob/master/learn/generation/openai/openai-ml-qa/01-making-queries.ipynb\n",
    "      - This notebook uses an older GPT 3 model for text generation\n",
    "- ILoveConference \n",
    "  - build index: https://github.com/iloveconference/models/blob/main/notebooks/20_index.ipynb\n",
    "  - make queries: https://github.com/iloveconference/server/blob/main/server/main.py#L111\n",
    "      - This notebook uses the new GPT 3.5 model for text generation. You should use this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc2b534",
   "metadata": {},
   "source": [
    "## Set API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc2a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"openai key value goes here\"\n",
    "PINECONE_API_KEY=\"pinecone key value goes here\"\n",
    "PINECONE_ENV=\"pinecone environment (region) goes here\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d845eac",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6a82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/ae/59/911d6e5f1d7514d79c527067643376cddcf4cb8d1728e599b3b03ab51c69/openai-0.28.0-py3-none-any.whl.metadata\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pinecone-client\n",
      "  Obtaining dependency information for pinecone-client from https://files.pythonhosted.org/packages/98/17/3675b83dca0a032d2750bf04fbfdf78a6e46fa3056eefc2574cdd14661d9/pinecone_client-2.2.2-py3-none-any.whl.metadata\n",
      "  Using cached pinecone_client-2.2.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/c3/05/c5c73d54ceb7d5e4b8c046d39a1bb7f38ee76ea556a002cf3317514f0196/pandas-2.1.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached pandas-2.1.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Collecting tqdm (from openai)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohttp (from openai)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/64/04/9ef622ccb6b340b3b53812e19f1658311614889452258eff91f6c9e1a1d9/aiohttp-3.8.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached aiohttp-3.8.5-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: pyyaml>=5.4 in ./.venv/lib/python3.11/site-packages (from pinecone-client) (6.0.1)\n",
      "Collecting loguru>=0.5.0 (from pinecone-client)\n",
      "  Obtaining dependency information for loguru>=0.5.0 from https://files.pythonhosted.org/packages/03/0a/4f6fed21aa246c6b49b561ca55facacc2a44b87d65b8b92362a8e99ba202/loguru-0.7.2-py3-none-any.whl.metadata\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting typing-extensions>=3.7.4 (from pinecone-client)\n",
      "  Obtaining dependency information for typing-extensions>=3.7.4 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting dnspython>=2.0.0 (from pinecone-client)\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/f6/b4/0a9bee52c50f226a3cbfb54263d02bb421c7f2adc136520729c2c689c1e5/dnspython-2.4.2-py3-none-any.whl.metadata\n",
      "  Using cached dnspython-2.4.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.11/site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in ./.venv/lib/python3.11/site-packages (from pinecone-client) (2.0.4)\n",
      "Collecting numpy>=1.22.0 (from pinecone-client)\n",
      "  Obtaining dependency information for numpy>=1.22.0 from https://files.pythonhosted.org/packages/c9/57/3cb8131a0e6d559501e088d3e685f4122e9ff9104c4b63e4dfd3a577b491/numpy-1.25.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached numpy-1.25.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Using cached pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Using cached multidict-6.0.4-cp311-cp311-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Using cached yarl-1.9.2-cp311-cp311-macosx_10_9_x86_64.whl (64 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1d/29/1a30aedecf5b6542f1dba92383352ccb35a3affcdf94bc5b2917dc95ce3b/frozenlist-1.4.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Using cached frozenlist-1.4.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Using cached pinecone_client-2.2.2-py3-none-any.whl (179 kB)\n",
      "Using cached pandas-2.1.0-cp311-cp311-macosx_10_9_x86_64.whl (12.0 MB)\n",
      "Using cached dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "Using cached loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Using cached numpy-1.25.2-cp311-cp311-macosx_10_9_x86_64.whl (20.8 MB)\n",
      "Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Using cached aiohttp-3.8.5-cp311-cp311-macosx_10_9_x86_64.whl (362 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached frozenlist-1.4.0-cp311-cp311-macosx_10_9_x86_64.whl (47 kB)\n",
      "Installing collected packages: pytz, tzdata, typing-extensions, tqdm, numpy, multidict, loguru, frozenlist, dnspython, async-timeout, yarl, pinecone-client, pandas, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 dnspython-2.4.2 frozenlist-1.4.0 loguru-0.7.2 multidict-6.0.4 numpy-1.25.2 openai-0.28.0 pandas-2.1.0 pinecone-client-2.2.2 pytz-2023.3.post1 tqdm-4.66.1 typing-extensions-4.7.1 tzdata-2023.3 yarl-1.9.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pinecone-client pandas\n",
    "# install other libraries as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007f145",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8ee239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dallan/dallanq/PathwayInternshipPresentations/.venv/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a946f4",
   "metadata": {},
   "source": [
    "## Initialize OpenAI and Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac035d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9be5c0b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead2b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"scriptures.csv\"\n",
    "data = pd.read_csv(data_path, names=['ref', 'text']).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c681b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the data to make sure you understand the format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26696fd3",
   "metadata": {},
   "source": [
    "## Generate embeddings\n",
    "\n",
    "Instead of generating embeddings in a separate step, you might want to generate the embeddings when you index the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code goes either here or in the indexing step below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c025c51",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing code codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a2236",
   "metadata": {},
   "source": [
    "## Ask a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ab41adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a question variable to a question you want to ask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e157e",
   "metadata": {},
   "source": [
    "## Generate an embedding for the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ff95540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generation code for the question goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7beca",
   "metadata": {},
   "source": [
    "## Query index for passages that are likely to answer to the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "269492e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61f4d1c",
   "metadata": {},
   "source": [
    "## Generate prompt from returned passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f936f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt generation code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487713b9",
   "metadata": {},
   "source": [
    "## Send prompt to text generation model and display the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ae33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation code goes here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PathwayInternshipPresentations",
   "language": "python",
   "name": "pathwayinternshippresentations"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
